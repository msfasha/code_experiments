{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Information Theory Analysis of Muqatta'at\n",
        "\n",
        "This notebook performs information theory analysis to test the hypothesis that Muqatta'at (المقطعات) function as checksums for Quranic text validation.\n",
        "\n",
        "## Analysis Objectives\n",
        "- Calculate Shannon entropy of letter distributions\n",
        "- Analyze compression ratios before/after removing Muqatta'at\n",
        "- Measure information content and predictive power\n",
        "- Calculate redundancy and test checksum hypothesis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.stats import entropy\n",
        "import gzip\n",
        "import zlib\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "# Import our data utilities\n",
        "from data_utils import load_quran_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and process the Quran data\n",
        "processor = load_quran_data(\"../datasets/quran-simple-clean.csv\")\n",
        "clean_df = processor.clean_dataset()\n",
        "\n",
        "print(f\"Dataset loaded: {len(clean_df)} verses from {clean_df['surah'].nunique()} surahs\")\n",
        "print(f\"Surahs with Muqatta'at: {len(processor.get_surahs_with_muqattaat())}\")\n",
        "print(f\"Surahs without Muqatta'at: {len(processor.get_surahs_without_muqattaat())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper functions for information theory calculations\n",
        "def calculate_shannon_entropy(text):\n",
        "    \"\"\"Calculate Shannon entropy of text.\"\"\"\n",
        "    if not text:\n",
        "        return 0\n",
        "    \n",
        "    # Count character frequencies\n",
        "    char_counts = Counter(text)\n",
        "    total_chars = len(text)\n",
        "    \n",
        "    # Calculate probabilities\n",
        "    probabilities = [count / total_chars for count in char_counts.values()]\n",
        "    \n",
        "    # Calculate Shannon entropy\n",
        "    return entropy(probabilities, base=2)\n",
        "\n",
        "def calculate_compression_ratio(text):\n",
        "    \"\"\"Calculate compression ratio using gzip.\"\"\"\n",
        "    if not text:\n",
        "        return 0\n",
        "    \n",
        "    original_size = len(text.encode('utf-8'))\n",
        "    compressed_size = len(gzip.compress(text.encode('utf-8')))\n",
        "    \n",
        "    return compressed_size / original_size if original_size > 0 else 0\n",
        "\n",
        "def calculate_redundancy(text):\n",
        "    \"\"\"Calculate redundancy = 1 - (H/H_max).\"\"\"\n",
        "    if not text:\n",
        "        return 0\n",
        "    \n",
        "    # Calculate entropy\n",
        "    H = calculate_shannon_entropy(text)\n",
        "    \n",
        "    # Maximum entropy (uniform distribution)\n",
        "    unique_chars = len(set(text))\n",
        "    H_max = np.log2(unique_chars) if unique_chars > 1 else 0\n",
        "    \n",
        "    return 1 - (H / H_max) if H_max > 0 else 0\n",
        "\n",
        "def calculate_mutual_information(text1, text2):\n",
        "    \"\"\"Calculate mutual information between two texts.\"\"\"\n",
        "    # Create joint frequency table\n",
        "    all_chars = set(text1 + text2)\n",
        "    joint_counts = Counter()\n",
        "    \n",
        "    for i in range(min(len(text1), len(text2))):\n",
        "        joint_counts[(text1[i], text2[i])] += 1\n",
        "    \n",
        "    # Calculate marginal probabilities\n",
        "    text1_counts = Counter(text1)\n",
        "    text2_counts = Counter(text2)\n",
        "    \n",
        "    total_pairs = sum(joint_counts.values())\n",
        "    if total_pairs == 0:\n",
        "        return 0\n",
        "    \n",
        "    # Calculate mutual information\n",
        "    mi = 0\n",
        "    for (c1, c2), count in joint_counts.items():\n",
        "        p_joint = count / total_pairs\n",
        "        p1 = text1_counts[c1] / len(text1) if len(text1) > 0 else 0\n",
        "        p2 = text2_counts[c2] / len(text2) if len(text2) > 0 else 0\n",
        "        \n",
        "        if p_joint > 0 and p1 > 0 and p2 > 0:\n",
        "            mi += p_joint * np.log2(p_joint / (p1 * p2))\n",
        "    \n",
        "    return mi\n",
        "\n",
        "print(\"Information theory helper functions defined.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Entropy Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate entropy for all surahs\n",
        "entropy_results = []\n",
        "\n",
        "for surah_num in sorted(clean_df['surah'].unique()):\n",
        "    # Get text with and without Muqatta'at\n",
        "    text_with = processor.get_surah_text(surah_num, include_muqattaat=True)\n",
        "    text_without = processor.get_surah_text(surah_num, include_muqattaat=False)\n",
        "    \n",
        "    # Calculate entropy\n",
        "    entropy_with = calculate_shannon_entropy(text_with)\n",
        "    entropy_without = calculate_shannon_entropy(text_without)\n",
        "    \n",
        "    # Calculate redundancy\n",
        "    redundancy_with = calculate_redundancy(text_with)\n",
        "    redundancy_without = calculate_redundancy(text_without)\n",
        "    \n",
        "    entropy_results.append({\n",
        "        'surah': surah_num,\n",
        "        'has_muqattaat': surah_num in processor.muqattaat_mapping,\n",
        "        'entropy_with': entropy_with,\n",
        "        'entropy_without': entropy_without,\n",
        "        'redundancy_with': redundancy_with,\n",
        "        'redundancy_without': redundancy_without,\n",
        "        'entropy_difference': entropy_with - entropy_without,\n",
        "        'redundancy_difference': redundancy_with - redundancy_without,\n",
        "        'text_length': len(text_without)\n",
        "    })\n",
        "\n",
        "entropy_df = pd.DataFrame(entropy_results)\n",
        "print(f\"Calculated entropy for {len(entropy_df)} surahs\")\n",
        "print(\"\\nEntropy Statistics:\")\n",
        "print(entropy_df[['entropy_with', 'entropy_without', 'entropy_difference']].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Compression Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate compression ratios for all surahs\n",
        "compression_results = []\n",
        "\n",
        "for surah_num in sorted(clean_df['surah'].unique()):\n",
        "    # Get text with and without Muqatta'at\n",
        "    text_with = processor.get_surah_text(surah_num, include_muqattaat=True)\n",
        "    text_without = processor.get_surah_text(surah_num, include_muqattaat=False)\n",
        "    \n",
        "    # Calculate compression ratios\n",
        "    comp_ratio_with = calculate_compression_ratio(text_with)\n",
        "    comp_ratio_without = calculate_compression_ratio(text_without)\n",
        "    \n",
        "    compression_results.append({\n",
        "        'surah': surah_num,\n",
        "        'has_muqattaat': surah_num in processor.muqattaat_mapping,\n",
        "        'compression_with': comp_ratio_with,\n",
        "        'compression_without': comp_ratio_without,\n",
        "        'compression_difference': comp_ratio_with - comp_ratio_without,\n",
        "        'text_length': len(text_without)\n",
        "    })\n",
        "\n",
        "compression_df = pd.DataFrame(compression_results)\n",
        "print(f\"Calculated compression ratios for {len(compression_df)} surahs\")\n",
        "print(\"\\nCompression Statistics:\")\n",
        "print(compression_df[['compression_with', 'compression_without', 'compression_difference']].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Checksum Hypothesis Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the checksum hypothesis by analyzing Muqatta'at predictive power\n",
        "checksum_analysis = []\n",
        "\n",
        "for surah_num in processor.get_surahs_with_muqattaat():\n",
        "    muqattaat_letters = processor.get_muqattaat_letters(surah_num)\n",
        "    surah_text = processor.get_surah_text(surah_num, include_muqattaat=False)\n",
        "    \n",
        "    # Calculate mutual information between Muqatta'at and surah content\n",
        "    # We'll use the first part of the surah to test predictive power\n",
        "    first_part = surah_text[:len(surah_text)//2]  # First half of surah\n",
        "    \n",
        "    # Create a \"prediction\" based on Muqatta'at letters\n",
        "    muqattaat_prediction = muqattaat_letters * (len(first_part) // len(muqattaat_letters) + 1)\n",
        "    muqattaat_prediction = muqattaat_prediction[:len(first_part)]\n",
        "    \n",
        "    # Calculate mutual information\n",
        "    mi = calculate_mutual_information(muqattaat_prediction, first_part)\n",
        "    \n",
        "    # Calculate correlation between Muqatta'at letter frequencies and surah letter frequencies\n",
        "    muqattaat_freq = Counter(muqattaat_letters)\n",
        "    surah_freq = Counter(surah_text)\n",
        "    \n",
        "    # Get common letters\n",
        "    common_letters = set(muqattaat_letters) & set(surah_text)\n",
        "    \n",
        "    if common_letters:\n",
        "        muqattaat_probs = [muqattaat_freq[letter] / len(muqattaat_letters) for letter in common_letters]\n",
        "        surah_probs = [surah_freq[letter] / len(surah_text) for letter in common_letters]\n",
        "        correlation = np.corrcoef(muqattaat_probs, surah_probs)[0, 1] if len(muqattaat_probs) > 1 else 0\n",
        "    else:\n",
        "        correlation = 0\n",
        "    \n",
        "    checksum_analysis.append({\n",
        "        'surah': surah_num,\n",
        "        'muqattaat_letters': muqattaat_letters,\n",
        "        'mutual_information': mi,\n",
        "        'correlation': correlation,\n",
        "        'common_letters_count': len(common_letters),\n",
        "        'surah_length': len(surah_text)\n",
        "    })\n",
        "\n",
        "checksum_df = pd.DataFrame(checksum_analysis)\n",
        "print(f\"Analyzed checksum hypothesis for {len(checksum_df)} surahs with Muqatta'at\")\n",
        "print(\"\\nChecksum Analysis Statistics:\")\n",
        "print(checksum_df[['mutual_information', 'correlation', 'common_letters_count']].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive visualizations\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# Plot 1: Entropy comparison\n",
        "with_muqattaat_entropy = entropy_df[entropy_df['has_muqattaat'] == True]\n",
        "without_muqattaat_entropy = entropy_df[entropy_df['has_muqattaat'] == False]\n",
        "\n",
        "axes[0, 0].hist([with_muqattaat_entropy['entropy_without'], without_muqattaat_entropy['entropy_without']], \n",
        "                bins=15, alpha=0.7, label=['With Muqatta\\'at', 'Without Muqatta\\'at'])\n",
        "axes[0, 0].set_title('Entropy Distribution Comparison')\n",
        "axes[0, 0].set_xlabel('Shannon Entropy')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# Plot 2: Entropy difference for surahs with Muqatta'at\n",
        "axes[0, 1].scatter(with_muqattaat_entropy['surah'], with_muqattaat_entropy['entropy_difference'], \n",
        "                   alpha=0.7, s=60)\n",
        "axes[0, 1].set_title('Entropy Difference (With - Without Muqatta\\'at)')\n",
        "axes[0, 1].set_xlabel('Surah Number')\n",
        "axes[0, 1].set_ylabel('Entropy Difference')\n",
        "axes[0, 1].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
        "\n",
        "# Plot 3: Compression ratio comparison\n",
        "with_muqattaat_comp = compression_df[compression_df['has_muqattaat'] == True]\n",
        "without_muqattaat_comp = compression_df[compression_df['has_muqattaat'] == False]\n",
        "\n",
        "axes[0, 2].hist([with_muqattaat_comp['compression_without'], without_muqattaat_comp['compression_without']], \n",
        "                bins=15, alpha=0.7, label=['With Muqatta\\'at', 'Without Muqatta\\'at'])\n",
        "axes[0, 2].set_title('Compression Ratio Distribution')\n",
        "axes[0, 2].set_xlabel('Compression Ratio')\n",
        "axes[0, 2].set_ylabel('Frequency')\n",
        "axes[0, 2].legend()\n",
        "\n",
        "# Plot 4: Redundancy analysis\n",
        "axes[1, 0].scatter(entropy_df['text_length'], entropy_df['redundancy_without'], \n",
        "                   c=entropy_df['has_muqattaat'], alpha=0.7, s=60, cmap='viridis')\n",
        "axes[1, 0].set_title('Redundancy vs Text Length')\n",
        "axes[1, 0].set_xlabel('Text Length (characters)')\n",
        "axes[1, 0].set_ylabel('Redundancy')\n",
        "axes[1, 0].set_colorbar()\n",
        "\n",
        "# Plot 5: Mutual information analysis\n",
        "axes[1, 1].scatter(checksum_df['surah'], checksum_df['mutual_information'], \n",
        "                   alpha=0.7, s=60, color='orange')\n",
        "axes[1, 1].set_title('Mutual Information Between Muqatta\\'at and Surah Content')\n",
        "axes[1, 1].set_xlabel('Surah Number')\n",
        "axes[1, 1].set_ylabel('Mutual Information')\n",
        "\n",
        "# Plot 6: Correlation analysis\n",
        "axes[1, 2].scatter(checksum_df['surah'], checksum_df['correlation'], \n",
        "                   alpha=0.7, s=60, color='green')\n",
        "axes[1, 2].set_title('Correlation Between Muqatta\\'at and Surah Letter Frequencies')\n",
        "axes[1, 2].set_xlabel('Surah Number')\n",
        "axes[1, 2].set_ylabel('Correlation Coefficient')\n",
        "axes[1, 2].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Statistical Tests and Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical tests for information theory metrics\n",
        "print(\"INFORMATION THEORY ANALYSIS SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Entropy comparison\n",
        "entropy_with = with_muqattaat_entropy['entropy_without']\n",
        "entropy_without = without_muqattaat_entropy['entropy_without']\n",
        "\n",
        "t_stat_entropy, p_value_entropy = stats.ttest_ind(entropy_with, entropy_without)\n",
        "print(f\"\\nEntropy Analysis:\")\n",
        "print(f\"- Average entropy (with Muqatta'at): {entropy_with.mean():.4f}\")\n",
        "print(f\"- Average entropy (without Muqatta'at): {entropy_without.mean():.4f}\")\n",
        "print(f\"- T-test p-value: {p_value_entropy:.4f}\")\n",
        "print(f\"- Significant difference: {'Yes' if p_value_entropy < 0.05 else 'No'}\")\n",
        "\n",
        "# Compression comparison\n",
        "comp_with = with_muqattaat_comp['compression_without']\n",
        "comp_without = without_muqattaat_comp['compression_without']\n",
        "\n",
        "t_stat_comp, p_value_comp = stats.ttest_ind(comp_with, comp_without)\n",
        "print(f\"\\nCompression Analysis:\")\n",
        "print(f\"- Average compression ratio (with Muqatta'at): {comp_with.mean():.4f}\")\n",
        "print(f\"- Average compression ratio (without Muqatta'at): {comp_without.mean():.4f}\")\n",
        "print(f\"- T-test p-value: {p_value_comp:.4f}\")\n",
        "print(f\"- Significant difference: {'Yes' if p_value_comp < 0.05 else 'No'}\")\n",
        "\n",
        "# Checksum hypothesis results\n",
        "print(f\"\\nChecksum Hypothesis Testing:\")\n",
        "print(f\"- Average mutual information: {checksum_df['mutual_information'].mean():.4f}\")\n",
        "print(f\"- Average correlation: {checksum_df['correlation'].mean():.4f}\")\n",
        "print(f\"- Surahs with positive correlation: {len(checksum_df[checksum_df['correlation'] > 0])}\")\n",
        "print(f\"- Surahs with negative correlation: {len(checksum_df[checksum_df['correlation'] < 0])}\")\n",
        "\n",
        "# Key insights\n",
        "print(f\"\\nKey Insights:\")\n",
        "if p_value_entropy < 0.05:\n",
        "    print(\"✓ Significant difference in entropy between surahs with and without Muqatta'at\")\n",
        "else:\n",
        "    print(\"✗ No significant difference in entropy between the two groups\")\n",
        "\n",
        "if p_value_comp < 0.05:\n",
        "    print(\"✓ Significant difference in compression ratios between the two groups\")\n",
        "else:\n",
        "    print(\"✗ No significant difference in compression ratios between the two groups\")\n",
        "\n",
        "if checksum_df['correlation'].mean() > 0.1:\n",
        "    print(\"✓ Strong positive correlation between Muqatta'at and surah letter frequencies\")\n",
        "elif checksum_df['correlation'].mean() < -0.1:\n",
        "    print(\"✓ Strong negative correlation between Muqatta'at and surah letter frequencies\")\n",
        "else:\n",
        "    print(\"✗ Weak correlation between Muqatta'at and surah letter frequencies\")\n",
        "\n",
        "print(f\"\\nNext Steps:\")\n",
        "print(\"- Proceed to Frequency Domain analysis to detect spectral patterns\")\n",
        "print(\"- Investigate autocorrelation patterns in letter sequences\")\n",
        "print(\"- Consider advanced information theory metrics for deeper analysis\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

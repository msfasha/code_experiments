{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quran Quantitative Analysis\n",
        "## Statistical Analysis and Time Series Investigation\n",
        "\n",
        "This notebook implements comprehensive analysis of the Quran text from quantitative and time series perspectives.\n",
        "\n",
        "### Project Objectives:\n",
        "- Multi-level time series analysis (character, word, surah, ayah windows)\n",
        "- Investigation of Muqatta'at letters (المقطعات) as potential CRC checks\n",
        "- Statistical analysis of text patterns and distributions\n",
        "- Encoding scheme comparison for time series analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter, defaultdict\n",
        "import re\n",
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Arabic text processing\n",
        "import arabic_reshaper\n",
        "from bidi.algorithm import get_display\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_quran_data():\n",
        "    # Set up paths and working directory\n",
        "    project_root = Path.cwd()\n",
        "    data_path = project_root / \"datasets\" / \"quran-simple-clean.csv\"\n",
        "\n",
        "    print(f\"Project root: {project_root}\")\n",
        "    print(f\"Data path: {data_path}\")\n",
        "    print(f\"Data file exists: {data_path.exists()}\")\n",
        "\n",
        "    # Load the dataset\n",
        "    if data_path.exists():\n",
        "        df = pd.read_csv(data_path)\n",
        "        print(f\"Dataset loaded successfully\")\n",
        "        print(f\"Shape: {df.shape}\")\n",
        "        print(f\"Columns: {list(df.columns)}\")\n",
        "    else:\n",
        "        print(\"Data file not found. Please check the path.\")\n",
        "        df = None\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: /media/me/Active/mywork/coding/mycode/code_experiments/1_r_quran_analysis\n",
            "Data path: /media/me/Active/mywork/coding/mycode/code_experiments/1_r_quran_analysis/datasets/quran-simple-clean.csv\n",
            "Data file exists: True\n",
            "Dataset loaded successfully\n",
            "Shape: (6236, 3)\n",
            "Columns: ['surah', 'aya', 'text']\n"
          ]
        }
      ],
      "source": [
        "original_df = load_quran_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dsiplay dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>surah</th>\n",
              "      <th>aya</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>بسم الله الرحمن الرحيم</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>الحمد لله رب العالمين</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>الرحمن الرحيم</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>مالك يوم الدين</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>إياك نعبد وإياك نستعين</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6231</th>\n",
              "      <td>114</td>\n",
              "      <td>2</td>\n",
              "      <td>ملك الناس</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6232</th>\n",
              "      <td>114</td>\n",
              "      <td>3</td>\n",
              "      <td>إله الناس</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6233</th>\n",
              "      <td>114</td>\n",
              "      <td>4</td>\n",
              "      <td>من شر الوسواس الخناس</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6234</th>\n",
              "      <td>114</td>\n",
              "      <td>5</td>\n",
              "      <td>الذي يوسوس في صدور الناس</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6235</th>\n",
              "      <td>114</td>\n",
              "      <td>6</td>\n",
              "      <td>من الجنة والناس</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6236 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      surah  aya                      text\n",
              "0         1    1    بسم الله الرحمن الرحيم\n",
              "1         1    2     الحمد لله رب العالمين\n",
              "2         1    3             الرحمن الرحيم\n",
              "3         1    4            مالك يوم الدين\n",
              "4         1    5    إياك نعبد وإياك نستعين\n",
              "...     ...  ...                       ...\n",
              "6231    114    2                 ملك الناس\n",
              "6232    114    3                 إله الناس\n",
              "6233    114    4      من شر الوسواس الخناس\n",
              "6234    114    5  الذي يوسوس في صدور الناس\n",
              "6235    114    6           من الجنة والناس\n",
              "\n",
              "[6236 rows x 3 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "original_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Exploration and Basic Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== DATASET OVERVIEW ===\n",
            "Total verses: 6236\n",
            "Total surahs: 114\n",
            "Surah range: 1 to 114\n",
            "Ayah range: 1 to 286\n",
            "\n",
            "=== SAMPLE DATA ===\n",
            "   surah  aya                    text\n",
            "0      1    1  بسم الله الرحمن الرحيم\n",
            "1      1    2   الحمد لله رب العالمين\n",
            "2      1    3           الرحمن الرحيم\n",
            "3      1    4          مالك يوم الدين\n",
            "4      1    5  إياك نعبد وإياك نستعين\n",
            "\n",
            "=== DATA TYPES ===\n",
            "surah     int64\n",
            "aya       int64\n",
            "text     object\n",
            "dtype: object\n",
            "\n",
            "=== MISSING VALUES ===\n",
            "surah    0\n",
            "aya      0\n",
            "text     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "if original_df is not None:\n",
        "    print(\"=== DATASET OVERVIEW ===\")\n",
        "    print(f\"Total verses: {len(original_df)}\")\n",
        "    print(f\"Total surahs: {original_df['surah'].nunique()}\")\n",
        "    print(f\"Surah range: {original_df['surah'].min()} to {original_df['surah'].max()}\")\n",
        "    print(f\"Ayah range: {original_df['aya'].min()} to {original_df['aya'].max()}\")\n",
        "    \n",
        "    print(\"\\n=== SAMPLE DATA ===\")\n",
        "    print(original_df.head())\n",
        "    \n",
        "    print(\"\\n=== DATA TYPES ===\")\n",
        "    print(original_df.dtypes)\n",
        "    \n",
        "    print(\"\\n=== MISSING VALUES ===\")\n",
        "    print(original_df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Text Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we need to remove Basmala, display the first aya of each sura"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First aya of each sura:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>surah</th>\n",
              "      <th>aya</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>بسم الله الرحمن الرحيم</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>بسم الله الرحمن الرحيم الم</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>بسم الله الرحمن الرحيم الم</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>بسم الله الرحمن الرحيم يا أيها الناس اتقوا ربك...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>بسم الله الرحمن الرحيم يا أيها الذين آمنوا أوف...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>110</td>\n",
              "      <td>1</td>\n",
              "      <td>بسم الله الرحمن الرحيم إذا جاء نصر الله والفتح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>111</td>\n",
              "      <td>1</td>\n",
              "      <td>بسم الله الرحمن الرحيم تبت يدا أبي لهب وتب</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>112</td>\n",
              "      <td>1</td>\n",
              "      <td>بسم الله الرحمن الرحيم قل هو الله أحد</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>113</td>\n",
              "      <td>1</td>\n",
              "      <td>بسم الله الرحمن الرحيم قل أعوذ برب الفلق</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>114</td>\n",
              "      <td>1</td>\n",
              "      <td>بسم الله الرحمن الرحيم قل أعوذ برب الناس</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     surah  aya                                               text\n",
              "0        1    1                             بسم الله الرحمن الرحيم\n",
              "1        2    1                         بسم الله الرحمن الرحيم الم\n",
              "2        3    1                         بسم الله الرحمن الرحيم الم\n",
              "3        4    1  بسم الله الرحمن الرحيم يا أيها الناس اتقوا ربك...\n",
              "4        5    1  بسم الله الرحمن الرحيم يا أيها الذين آمنوا أوف...\n",
              "..     ...  ...                                                ...\n",
              "109    110    1     بسم الله الرحمن الرحيم إذا جاء نصر الله والفتح\n",
              "110    111    1         بسم الله الرحمن الرحيم تبت يدا أبي لهب وتب\n",
              "111    112    1              بسم الله الرحمن الرحيم قل هو الله أحد\n",
              "112    113    1           بسم الله الرحمن الرحيم قل أعوذ برب الفلق\n",
              "113    114    1           بسم الله الرحمن الرحيم قل أعوذ برب الناس\n",
              "\n",
              "[114 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display the first aya of each sura\n",
        "if original_df is not None:\n",
        "    first_ayas = original_df[original_df['aya'] == 1][['surah', 'aya', 'text']]\n",
        "    print(\"First aya of each sura:\")\n",
        "    display(first_ayas.reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following code removes basmala from the first verse of each surah, knowing that many surahs have basmala in the first verse and also some of them has the second verse after basmala in the first verse so we need to account for that\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "basmala = 'بسم الله الرحمن الرحيم'\n",
        "\n",
        "def remove_basmala_from_first_aya(row):\n",
        "    if row['aya'] == 1 and (basmala in row['text']):\n",
        "        # If basmala is the only text (after stripping spaces and punctuation), do NOT remove it\n",
        "        stripped_text = row['text'].strip(' ،:;،.،')\n",
        "        if stripped_text == basmala:\n",
        "            return row['text']\n",
        "        # Remove only the first occurrence of basmala, and handle extra spaces or punctuation\n",
        "        new_text = row['text']\n",
        "        idx = new_text.find(basmala)\n",
        "        if idx != -1:\n",
        "            # Remove basmala and any following spaces or punctuation (like \"، \", etc.)\n",
        "            new_text = new_text[idx+len(basmala):].lstrip(' ،:;،.،')\n",
        "            # If the text is empty after basmala removal, return empty string\n",
        "            if new_text.strip() == '':\n",
        "                return ''\n",
        "            return new_text\n",
        "    return row['text']\n",
        "\n",
        "# Apply to the dataframe inplace (if not already done in preprocessing function)\n",
        "df_no_basmala = original_df.copy()\n",
        "df_no_basmala['text'] = df_no_basmala.apply(remove_basmala_from_first_aya, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display first aya again after moving Basmala"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First aya of each sura:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>surah</th>\n",
              "      <th>aya</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>بسم الله الرحمن الرحيم</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>الم</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>الم</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>يا أيها الناس اتقوا ربكم الذي خلقكم من نفس واح...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>يا أيها الذين آمنوا أوفوا بالعقود ۚ أحلت لكم ب...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>110</td>\n",
              "      <td>1</td>\n",
              "      <td>إذا جاء نصر الله والفتح</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>111</td>\n",
              "      <td>1</td>\n",
              "      <td>تبت يدا أبي لهب وتب</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>112</td>\n",
              "      <td>1</td>\n",
              "      <td>قل هو الله أحد</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>113</td>\n",
              "      <td>1</td>\n",
              "      <td>قل أعوذ برب الفلق</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>114</td>\n",
              "      <td>1</td>\n",
              "      <td>قل أعوذ برب الناس</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     surah  aya                                               text\n",
              "0        1    1                             بسم الله الرحمن الرحيم\n",
              "1        2    1                                                الم\n",
              "2        3    1                                                الم\n",
              "3        4    1  يا أيها الناس اتقوا ربكم الذي خلقكم من نفس واح...\n",
              "4        5    1  يا أيها الذين آمنوا أوفوا بالعقود ۚ أحلت لكم ب...\n",
              "..     ...  ...                                                ...\n",
              "109    110    1                            إذا جاء نصر الله والفتح\n",
              "110    111    1                                تبت يدا أبي لهب وتب\n",
              "111    112    1                                     قل هو الله أحد\n",
              "112    113    1                                  قل أعوذ برب الفلق\n",
              "113    114    1                                  قل أعوذ برب الناس\n",
              "\n",
              "[114 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display the first aya of each sura\n",
        "if df is not None:\n",
        "    first_ayas = df[df['aya'] == 1][['surah', 'aya', 'text']]\n",
        "    print(\"First aya of each sura:\")\n",
        "    display(first_ayas.reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can choose to keep or remove the Basamla from surat Al Fatihah, it is debated between scientists whether it is a verse or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "(0,)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m/media/me/Active/mywork/coding/mycode/code_experiments/1_r_quran_analysis/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyError\u001b[39m: (0,)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_no_basmala\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_no_basmala\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msurah\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m]\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/media/me/Active/mywork/coding/mycode/code_experiments/1_r_quran_analysis/venv/lib/python3.12/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/media/me/Active/mywork/coding/mycode/code_experiments/1_r_quran_analysis/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
            "\u001b[31mKeyError\u001b[39m: (0,)"
          ]
        }
      ],
      "source": [
        "# Display the first aya of surat Al Fatihah\n",
        "if df_no_basmala is not None:\n",
        "    fatihah_aya = df_no_basmala[df_no_basmala['surah'] == 1][['surah', 'aya', 'text']]\n",
        "    print(\"First aya of surat Al Fatihah:\")\n",
        "    display(fatihah_aya.reset_index(drop=True))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "if df is not None:\n",
        "    print (\"not null\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original verses: 6236\n",
            "After cleaning: 6235\n",
            "Removed: 1 empty verses\n",
            "\n",
            "=== SAMPLE CLEANED TEXT ===\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'sura'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m/media/me/Active/mywork/coding/mycode/code_experiments/1_r_quran_analysis/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyError\u001b[39m: 'sura'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== SAMPLE CLEANED TEXT ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSurah \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdf_processed\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msura\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Ayah \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_processed.iloc[i][\u001b[33m'\u001b[39m\u001b[33maya\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_processed.iloc[i][\u001b[33m'\u001b[39m\u001b[33mtext_clean\u001b[39m\u001b[33m'\u001b[39m][:\u001b[32m50\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/media/me/Active/mywork/coding/mycode/code_experiments/1_r_quran_analysis/venv/lib/python3.12/site-packages/pandas/core/series.py:1133\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1136\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/media/me/Active/mywork/coding/mycode/code_experiments/1_r_quran_analysis/venv/lib/python3.12/site-packages/pandas/core/series.py:1249\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1248\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/media/me/Active/mywork/coding/mycode/code_experiments/1_r_quran_analysis/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
            "\u001b[31mKeyError\u001b[39m: 'sura'"
          ]
        }
      ],
      "source": [
        "def clean_quran_text(df):\n",
        "    \"\"\"Clean and preprocess Quran text for analysis\"\"\"\n",
        "    df_clean = df.copy()\n",
        "    \n",
        "    # Remove Basmala from first verse of each surah\n",
        "    basmala = 'بسم الله الرحمن الرحيم'\n",
        "    \n",
        "    def remove_basmala(row):\n",
        "        if row['aya'] == 1 and row['text'].startswith(basmala):\n",
        "            return row['text'][len(basmala):].strip()\n",
        "        return row['text']\n",
        "    \n",
        "    df_clean['text'] = df_clean.apply(remove_basmala, axis=1)\n",
        "    \n",
        "    # Remove diacritics and non-Arabic characters (keeping only Arabic letters and spaces)\n",
        "    df_clean['text_clean'] = df_clean['text'].str.replace(r'[^ء-ي\\s]', '', regex=True)\n",
        "    df_clean['text_clean'] = df_clean['text_clean'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "    \n",
        "    # Keep original text with diacritics for comparison\n",
        "    df_clean['text_with_diacritics'] = df_clean['text']\n",
        "    \n",
        "    # Remove empty verses after cleaning\n",
        "    df_clean = df_clean[df_clean['text_clean'] != ''].copy()\n",
        "    \n",
        "    return df_clean\n",
        "\n",
        "if df is not None:\n",
        "    df_processed = clean_quran_text(df)\n",
        "    print(f\"Original verses: {len(df)}\")\n",
        "    print(f\"After cleaning: {len(df_processed)}\")\n",
        "    print(f\"Removed: {len(df) - len(df_processed)} empty verses\")\n",
        "    \n",
        "    print(\"\\n=== SAMPLE CLEANED TEXT ===\")\n",
        "    for i in range(3):\n",
        "        print(f\"Surah {df_processed.iloc[i]['sura']}, Ayah {df_processed.iloc[i]['aya']}: {df_processed.iloc[i]['text_clean'][:50]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Basic Statistical Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_basic_stats(df):\n",
        "    \"\"\"Calculate basic statistical measures for the text\"\"\"\n",
        "    stats = {}\n",
        "    \n",
        "    # Character-level statistics\n",
        "    all_text = ' '.join(df['text_clean'])\n",
        "    stats['total_characters'] = len(all_text)\n",
        "    stats['unique_characters'] = len(set(all_text.replace(' ', '')))\n",
        "    stats['total_words'] = len(all_text.split())\n",
        "    stats['unique_words'] = len(set(all_text.split()))\n",
        "    \n",
        "    # Per verse statistics\n",
        "    df['char_count'] = df['text_clean'].str.len()\n",
        "    df['word_count'] = df['text_clean'].str.split().str.len()\n",
        "    \n",
        "    stats['avg_chars_per_verse'] = df['char_count'].mean()\n",
        "    stats['avg_words_per_verse'] = df['word_count'].mean()\n",
        "    stats['std_chars_per_verse'] = df['char_count'].std()\n",
        "    stats['std_words_per_verse'] = df['word_count'].std()\n",
        "    \n",
        "    # Per surah statistics\n",
        "    surah_stats = df.groupby('surah').agg({\n",
        "        'char_count': ['sum', 'mean', 'std'],\n",
        "        'word_count': ['sum', 'mean', 'std'],\n",
        "        'aya': 'count'\n",
        "    }).round(2)\n",
        "    \n",
        "    stats['surah_stats'] = surah_stats\n",
        "    \n",
        "    return stats, df\n",
        "\n",
        "if 'df_processed' in locals():\n",
        "    stats, df_with_stats = calculate_basic_stats(df_processed)\n",
        "    \n",
        "    print(\"=== BASIC STATISTICS ===\")\n",
        "    for key, value in stats.items():\n",
        "        if key != 'surah_stats':\n",
        "            print(f\"{key}: {value}\")\n",
        "    \n",
        "    print(\"\\n=== PER VERSE STATISTICS ===\")\n",
        "    print(f\"Character count - Mean: {stats['avg_chars_per_verse']:.2f}, Std: {stats['std_chars_per_verse']:.2f}\")\n",
        "    print(f\"Word count - Mean: {stats['avg_words_per_verse']:.2f}, Std: {stats['std_words_per_verse']:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize basic distributions\n",
        "if 'df_with_stats' in locals():\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    # Character count distribution\n",
        "    axes[0, 0].hist(df_with_stats['char_count'], bins=50, alpha=0.7, color='skyblue')\n",
        "    axes[0, 0].set_title('Distribution of Characters per Verse')\n",
        "    axes[0, 0].set_xlabel('Character Count')\n",
        "    axes[0, 0].set_ylabel('Frequency')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Word count distribution\n",
        "    axes[0, 1].hist(df_with_stats['word_count'], bins=50, alpha=0.7, color='lightgreen')\n",
        "    axes[0, 1].set_title('Distribution of Words per Verse')\n",
        "    axes[0, 1].set_xlabel('Word Count')\n",
        "    axes[0, 1].set_ylabel('Frequency')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Characters vs Words scatter\n",
        "    axes[1, 0].scatter(df_with_stats['char_count'], df_with_stats['word_count'], alpha=0.5, s=1)\n",
        "    axes[1, 0].set_title('Characters vs Words per Verse')\n",
        "    axes[1, 0].set_xlabel('Character Count')\n",
        "    axes[1, 0].set_ylabel('Word Count')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Surah length distribution\n",
        "    surah_lengths = df_with_stats.groupby('surah')['aya'].count()\n",
        "    axes[1, 1].bar(range(1, len(surah_lengths)+1), surah_lengths.values, alpha=0.7, color='orange')\n",
        "    axes[1, 1].set_title('Number of Verses per Surah')\n",
        "    axes[1, 1].set_xlabel('Surah Number')\n",
        "    axes[1, 1].set_ylabel('Number of Verses')\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print some interesting statistics\n",
        "    print(\"\\n=== INTERESTING STATISTICS ===\")\n",
        "    print(f\"Longest verse: {df_with_stats.loc[df_with_stats['char_count'].idxmax(), 'char_count']} characters\")\n",
        "    print(f\"Shortest verse: {df_with_stats.loc[df_with_stats['char_count'].idxmin(), 'char_count']} characters\")\n",
        "    print(f\"Longest surah: Surah {surah_lengths.idxmax()} with {surah_lengths.max()} verses\")\n",
        "    print(f\"Shortest surah: Surah {surah_lengths.idxmin()} with {surah_lengths.min()} verses\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Character-Level Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_characters(df):\n",
        "    \"\"\"Analyze character frequency and patterns\"\"\"\n",
        "    # Combine all text\n",
        "    all_text = ' '.join(df['text_clean'])\n",
        "    \n",
        "    # Character frequency\n",
        "    char_freq = Counter(all_text.replace(' ', ''))\n",
        "    \n",
        "    # Create character analysis dataframe\n",
        "    char_df = pd.DataFrame(char_freq.most_common(), columns=['character', 'frequency'])\n",
        "    char_df['percentage'] = (char_df['frequency'] / char_df['frequency'].sum()) * 100\n",
        "    \n",
        "    return char_df, all_text\n",
        "\n",
        "if 'df_with_stats' in locals():\n",
        "    char_df, all_text = analyze_characters(df_with_stats)\n",
        "    \n",
        "    print(\"=== CHARACTER FREQUENCY ANALYSIS ===\")\n",
        "    print(f\"Total unique characters: {len(char_df)}\")\n",
        "    print(f\"Total characters (excluding spaces): {char_df['frequency'].sum()}\")\n",
        "    \n",
        "    print(\"\\n=== TOP 20 MOST FREQUENT CHARACTERS ===\")\n",
        "    print(char_df.head(20).to_string(index=False))\n",
        "    \n",
        "    # Visualize character frequency\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    top_chars = char_df.head(20)\n",
        "    \n",
        "    # Create display names for Arabic characters\n",
        "    top_chars['display_name'] = top_chars['character'].apply(\n",
        "        lambda x: get_display(arabic_reshaper.reshape(x)) if x != ' ' else 'Space'\n",
        "    )\n",
        "    \n",
        "    plt.barh(range(len(top_chars)), top_chars['frequency'])\n",
        "    plt.yticks(range(len(top_chars)), top_chars['display_name'])\n",
        "    plt.xlabel('Frequency')\n",
        "    plt.title('Top 20 Most Frequent Characters in Quran')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.grid(axis='x', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Muqatta'at Letters Analysis (CRC Hypothesis)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_muqattaat(df):\n",
        "    \"\"\"Analyze Muqatta'at letters and their patterns\"\"\"\n",
        "    \n",
        "    # Define Muqatta'at letters (المقطعات)\n",
        "    muqattaat_letters = {\n",
        "        'alif_lam_mim': ['ا', 'ل', 'م'],\n",
        "        'alif_lam_mim_sad': ['ا', 'ل', 'م', 'ص'],\n",
        "        'alif_lam_ra': ['ا', 'ل', 'ر'],\n",
        "        'kaf_ha_ya_ain_sad': ['ك', 'ه', 'ي', 'ع', 'ص'],\n",
        "        'ta_ha': ['ط', 'ه'],\n",
        "        'ta_sin_mim': ['ط', 'س', 'م'],\n",
        "        'ta_sin': ['ط', 'س'],\n",
        "        'ya_sin': ['ي', 'س'],\n",
        "        'sad': ['ص'],\n",
        "        'ha_mim': ['ح', 'م'],\n",
        "        'ain_sin_qaf': ['ع', 'س', 'ق'],\n",
        "        'qaf': ['ق'],\n",
        "        'nun': ['ن']\n",
        "    }\n",
        "    \n",
        "    # Get all unique Muqatta'at letters\n",
        "    all_muqattaat = set()\n",
        "    for letters in muqattaat_letters.values():\n",
        "        all_muqattaat.update(letters)\n",
        "    \n",
        "    # Analyze frequency of Muqatta'at letters\n",
        "    all_text = ' '.join(df['text_clean'])\n",
        "    char_freq = Counter(all_text.replace(' ', ''))\n",
        "    \n",
        "    muqattaat_freq = {char: char_freq.get(char, 0) for char in all_muqattaat}\n",
        "    \n",
        "    # Calculate statistics\n",
        "    total_chars = sum(char_freq.values())\n",
        "    muqattaat_total = sum(muqattaat_freq.values())\n",
        "    muqattaat_percentage = (muqattaat_total / total_chars) * 100\n",
        "    \n",
        "    return {\n",
        "        'muqattaat_letters': all_muqattaat,\n",
        "        'muqattaat_freq': muqattaat_freq,\n",
        "        'total_muqattaat': muqattaat_total,\n",
        "        'muqattaat_percentage': muqattaat_percentage,\n",
        "        'muqattaat_groups': muqattaat_letters\n",
        "    }\n",
        "\n",
        "if 'df_with_stats' in locals():\n",
        "    muqattaat_analysis = analyze_muqattaat(df_with_stats)\n",
        "    \n",
        "    print(\"=== MUQATTA'AT LETTERS ANALYSIS ===\")\n",
        "    print(f\"Total Muqatta'at letters: {len(muqattaat_analysis['muqattaat_letters'])}\")\n",
        "    print(f\"Total frequency of Muqatta'at letters: {muqattaat_analysis['total_muqattaat']}\")\n",
        "    print(f\"Percentage of text: {muqattaat_analysis['muqattaat_percentage']:.2f}%\")\n",
        "    \n",
        "    print(\"\\n=== MUQATTA'AT LETTER FREQUENCIES ===\")\n",
        "    muqattaat_df = pd.DataFrame(\n",
        "        list(muqattaat_analysis['muqattaat_freq'].items()),\n",
        "        columns=['letter', 'frequency']\n",
        "    ).sort_values('frequency', ascending=False)\n",
        "    \n",
        "    # Add display names\n",
        "    muqattaat_df['display_name'] = muqattaat_df['letter'].apply(\n",
        "        lambda x: get_display(arabic_reshaper.reshape(x))\n",
        "    )\n",
        "    \n",
        "    print(muqattaat_df.to_string(index=False))\n",
        "    \n",
        "    # Visualize Muqatta'at frequency\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.bar(muqattaat_df['display_name'], muqattaat_df['frequency'])\n",
        "    plt.title('Frequency of Muqatta\\\\'at Letters')\n",
        "    plt.xlabel('Letter')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Time Series Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_time_series_data(df, encoding_scheme='unicode'):\n",
        "    \"\"\"Prepare data for time series analysis with different encoding schemes\"\"\"\n",
        "    \n",
        "    time_series_data = []\n",
        "    \n",
        "    for idx, row in df.iterrows():\n",
        "        text = row['text_clean']\n",
        "        surah = row['surah']\n",
        "        aya = row['aya']\n",
        "        \n",
        "        if encoding_scheme == 'unicode':\n",
        "            # Unicode values\n",
        "            encoded = [ord(char) for char in text if char != ' ']\n",
        "        elif encoding_scheme == 'sequential':\n",
        "            # Sequential ordering (1, 2, 3, ...)\n",
        "            unique_chars = list(set(text.replace(' ', '')))\n",
        "            char_to_num = {char: i+1 for i, char in enumerate(unique_chars)}\n",
        "            encoded = [char_to_num.get(char, 0) for char in text if char != ' ']\n",
        "        elif encoding_scheme == 'muqattaat_focus':\n",
        "            # Focus on Muqatta'at letters only\n",
        "            muqattaat_letters = {'ا', 'ل', 'م', 'ص', 'ر', 'ك', 'ه', 'ي', 'ع', 'ط', 'س', 'ح', 'ق', 'ن'}\n",
        "            encoded = [ord(char) if char in muqattaat_letters else 0 for char in text if char != ' ']\n",
        "        \n",
        "        time_series_data.append({\n",
        "            'surah': surah,\n",
        "            'aya': aya,\n",
        "            'encoded_sequence': encoded,\n",
        "            'sequence_length': len(encoded),\n",
        "            'text': text\n",
        "        })\n",
        "    \n",
        "    return pd.DataFrame(time_series_data)\n",
        "\n",
        "if 'df_with_stats' in locals():\n",
        "    # Test different encoding schemes\n",
        "    print(\"=== TIME SERIES DATA PREPARATION ===\")\n",
        "    \n",
        "    # Unicode encoding\n",
        "    ts_unicode = prepare_time_series_data(df_with_stats, 'unicode')\n",
        "    print(f\"Unicode encoding - Sample sequence: {ts_unicode.iloc[0]['encoded_sequence'][:10]}...\")\n",
        "    \n",
        "    # Muqatta'at focus encoding\n",
        "    ts_muqattaat = prepare_time_series_data(df_with_stats, 'muqattaat_focus')\n",
        "    print(f\"Muqatta'at focus - Sample sequence: {ts_muqattaat.iloc[0]['encoded_sequence'][:10]}...\")\n",
        "    \n",
        "    # Calculate some basic time series statistics\n",
        "    print(f\"\\n=== TIME SERIES STATISTICS ===\")\n",
        "    print(f\"Average sequence length: {ts_unicode['sequence_length'].mean():.2f}\")\n",
        "    print(f\"Sequence length std: {ts_unicode['sequence_length'].std():.2f}\")\n",
        "    print(f\"Total sequences: {len(ts_unicode)}\")\n",
        "    \n",
        "    # Show distribution of sequence lengths\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.hist(ts_unicode['sequence_length'], bins=50, alpha=0.7, color='skyblue')\n",
        "    plt.title('Distribution of Sequence Lengths (Unicode)')\n",
        "    plt.xlabel('Sequence Length')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(ts_muqattaat['sequence_length'], bins=50, alpha=0.7, color='lightcoral')\n",
        "    plt.title('Distribution of Sequence Lengths (Muqatta\\\\'at Focus)')\n",
        "    plt.xlabel('Sequence Length')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Rolling Window Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rolling_window_analysis(df, window_size=10):\n",
        "    \"\"\"Analyze patterns in rolling windows of verses\"\"\"\n",
        "    \n",
        "    # Calculate rolling statistics\n",
        "    df['rolling_char_mean'] = df['char_count'].rolling(window=window_size, min_periods=1).mean()\n",
        "    df['rolling_word_mean'] = df['word_count'].rolling(window=window_size, min_periods=1).mean()\n",
        "    df['rolling_char_std'] = df['char_count'].rolling(window=window_size, min_periods=1).std()\n",
        "    df['rolling_word_std'] = df['word_count'].rolling(window=window_size, min_periods=1).std()\n",
        "    \n",
        "    return df\n",
        "\n",
        "if 'df_with_stats' in locals():\n",
        "    # Apply rolling window analysis\n",
        "    df_rolling = rolling_window_analysis(df_with_stats, window_size=10)\n",
        "    \n",
        "    print(\"=== ROLLING WINDOW ANALYSIS (Window Size: 10) ===\")\n",
        "    \n",
        "    # Visualize rolling patterns\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    # Rolling character mean\n",
        "    axes[0, 0].plot(df_rolling.index, df_rolling['rolling_char_mean'], alpha=0.7, color='blue')\n",
        "    axes[0, 0].set_title('Rolling Mean of Character Count (Window=10)')\n",
        "    axes[0, 0].set_xlabel('Verse Index')\n",
        "    axes[0, 0].set_ylabel('Mean Character Count')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Rolling word mean\n",
        "    axes[0, 1].plot(df_rolling.index, df_rolling['rolling_word_mean'], alpha=0.7, color='green')\n",
        "    axes[0, 1].set_title('Rolling Mean of Word Count (Window=10)')\n",
        "    axes[0, 1].set_xlabel('Verse Index')\n",
        "    axes[0, 1].set_ylabel('Mean Word Count')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Rolling character std\n",
        "    axes[1, 0].plot(df_rolling.index, df_rolling['rolling_char_std'], alpha=0.7, color='red')\n",
        "    axes[1, 0].set_title('Rolling Std of Character Count (Window=10)')\n",
        "    axes[1, 0].set_xlabel('Verse Index')\n",
        "    axes[1, 0].set_ylabel('Std Character Count')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Rolling word std\n",
        "    axes[1, 1].plot(df_rolling.index, df_rolling['rolling_word_std'], alpha=0.7, color='orange')\n",
        "    axes[1, 1].set_title('Rolling Std of Word Count (Window=10)')\n",
        "    axes[1, 1].set_xlabel('Verse Index')\n",
        "    axes[1, 1].set_ylabel('Std Word Count')\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print some statistics about the rolling analysis\n",
        "    print(f\"\\nRolling Character Mean - Min: {df_rolling['rolling_char_mean'].min():.2f}, Max: {df_rolling['rolling_char_mean'].max():.2f}\")\n",
        "    print(f\"Rolling Word Mean - Min: {df_rolling['rolling_word_mean'].min():.2f}, Max: {df_rolling['rolling_word_mean'].max():.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary and Next Steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== ANALYSIS SUMMARY ===\")\n",
        "print(\"\\n1. Data Quality:\")\n",
        "if 'df_processed' in locals():\n",
        "    print(f\"   - Successfully processed {len(df_processed)} verses\")\n",
        "    print(f\"   - Removed {len(df) - len(df_processed)} empty verses after cleaning\")\n",
        "\n",
        "print(\"\\n2. Statistical Findings:\")\n",
        "if 'stats' in locals():\n",
        "    print(f\"   - Total characters: {stats['total_characters']:,}\")\n",
        "    print(f\"   - Unique characters: {stats['unique_characters']}\")\n",
        "    print(f\"   - Total words: {stats['total_words']:,}\")\n",
        "    print(f\"   - Unique words: {stats['unique_words']:,}\")\n",
        "    print(f\"   - Average characters per verse: {stats['avg_chars_per_verse']:.2f}\")\n",
        "    print(f\"   - Average words per verse: {stats['avg_words_per_verse']:.2f}\")\n",
        "\n",
        "print(\"\\n3. Muqatta'at Analysis:\")\n",
        "if 'muqattaat_analysis' in locals():\n",
        "    print(f\"   - Muqatta'at letters represent {muqattaat_analysis['muqattaat_percentage']:.2f}% of all text\")\n",
        "    print(f\"   - Total Muqatta'at letter frequency: {muqattaat_analysis['total_muqattaat']:,}\")\n",
        "\n",
        "print(\"\\n4. Time Series Preparation:\")\n",
        "if 'ts_unicode' in locals():\n",
        "    print(f\"   - Prepared {len(ts_unicode)} sequences for time series analysis\")\n",
        "    print(f\"   - Average sequence length: {ts_unicode['sequence_length'].mean():.2f}\")\n",
        "\n",
        "print(\"\\n=== RECOMMENDED NEXT STEPS ===\")\n",
        "print(\"1. Implement autocorrelation analysis on the time series data\")\n",
        "print(\"2. Apply spectral analysis (FFT) to detect periodic patterns\")\n",
        "print(\"3. Test the CRC hypothesis by analyzing Muqatta'at letter distributions\")\n",
        "print(\"4. Implement entropy analysis for information content\")\n",
        "print(\"5. Create surah-level pattern analysis\")\n",
        "print(\"6. Compare different encoding schemes systematically\")\n",
        "print(\"7. Implement rolling window analysis with different window sizes\")\n",
        "print(\"8. Add diacritics analysis for comparison\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
